{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b423382",
   "metadata": {},
   "source": [
    "# WEB CRAWLER with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a4748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.firecrawl import FireCrawlLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c49902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.goldmansachs.com/insights/articles/the-outlook-for-ai-adoption-as-advancements-in-the-technology-accelerate\")\n",
    "loader.requests_kwargs = {\"verify\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6111a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuszbronowicki/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.goldmansachs.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179f05df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The outlook for AI adoption as advancements in the technology accelerate  | Goldman Sachs\n",
      "\n",
      "What We Dokeyboard_arrow_downInsightskeyboard_arrow_downOur Firmkeyboard_arrow_downCareerskeyboard_arrow_downInvestor RelationsInvestor RelationsPressroomPressroomWorldwideWorldwideAlumniAlumnisearchsearchClient LoginClient LoginWhat We Dokeyboard_arrow_downInsightskeyboard_arrow_downOur Firmkeyboard_arrow_downCareerskeyboard_arrow_downInvestor RelationsInvestor RelationsPressroomPressroomWorldwideWorldwideAlumniAlumnisearchsearchClient LoginClient LoginWhat We Dokeyboard_arrow_downInsightskeyboard_arrow_downOur Firmkeyboard_arrow_downCareerskeyboard_arrow_downInvestor RelationsInvestor RelationsPressroomPressroomWorldwideWorldwideAlumniAlumnisearchsearchClient LoginClient LoginWhat We Dokeyboard_arrow_downInsightskeyboard_arrow_downOur Firmkeyboard_arrow_downCareerskeyboard_arrow_downInvestor RelationsInvestor RelationsPressroomPressroomWorldwideWorldwideAlumniAlumnisearchsearchClient LoginClient LogincloseSearchsearchArtificial IntelligenceThe outlook for AI adoption as advancements in the technology accelerateJun 9, 2025ShareshareThere are signs that artificial intelligence (AI) is exceeding even the bullish expectations of 2024. Usage of the most popular models has risen substantially, while the amount of investment in AI from the largest hyperscale technology companies is forecast to be about double what was predicted, says George Lee, co-head of the Goldman Sachs Global Institute. AI is helping to build more advanced generations itself and has the potential to accelerate invention.\n",
      "In short, technical achievements in AI are racing ahead. But even so, some important questions remain about the technology’s ultimate impact on the economy and corporations’ bottom line. Enterprise adoption of AI still must prove itself and overcome corporate inertia, and reasonable questions remain about the return on the extraordinary level of investment, Lee says in an interview with Tony Pasquariello, global head of Hedge Fund Coverage, on the Breaks of the Game podcast.\n",
      "Pasquariello spoke with Lee, about investor sentiment toward AI, the impact of tariffs on the AI investment landscape, and the future of AI innovation. \n",
      "This conversation was originally recorded on May 24, 2025. Below are excerpts from the discussion. The full podcast episode is available to GS Institutional Clients on Marquee here.\n",
      "It's been a little bit over a year since we last discussed the AI revolution. So let's start with just a quick mark to market about what has changed. \n",
      "We last talked on Breaks of the Game in the middle of March 2024. And in some ways that feels like yesterday. Yet in AI terms, it feels like that was the Paleozoic era. So much change, so much progress. And yet, as I'm sure we'll get to, there are some persistent questions that remain. So, I went back and wrote down a few comparisons from that March 2024 period to today — and AI may or may not have contributed to this — but here's just some interesting data.\n",
      "OpenAI’s weekly average users when we talked last was approximately 180 million. Today, that's north of 800 million, probably north of a billion.\n",
      "The price of API tokens from leading models has declined about 100x since we talked last.\n",
      "The number of tokens consumed on a platform called OpenRouter, which is kind of a proxy for coding agents, is up about 75x since then.\n",
      "Back then the 2026 capex expectations for the four principal hyperscalers was about $207 billion. Today, it's $405 billion.\n",
      "In March 2024, most observers hadn't heard of DeepSeek, Stargate, reasoning models, Elon's Colossus, and on and on.\n",
      "It's a really extraordinary rate of change. But there are still some big questions: questions about enterprise adoption, reasonable questions about the ROI on all this capital spend, questions about what the winning business models will be.\n",
      "There’s one question I get asked a lot about, which is what killer app has emerged in this period of time. I have an answer to that, which I’m sure we’ll get to.\n",
      "Those are all eye-popping statistics. The capex, from $207 billion to $405 billion, is probably the most intuitive for interlopers like me. But would you say when you take stock of it all, and again when you look back to March of last year, would you say the collective pace of advancement has exceeded what I think were already your high expectations?\n",
      "In the dimension of technical progress, absolutely. We're finding our way into the future here. Sitting a year, or year and a half ago, it was unclear whether we'd run into some glass ceiling or unforeseen stopper of progress, and even during the intervening period, there have been questions about the scaling laws being over, etc. And we've just continued to motor through barrier after barrier. The rate of technical change is higher and more sustained than I might have expected.\n",
      "I think enterprise adoption is probably fairly consistent with my expectations, because, as we talked about then, that's sticky. There are a lot of inertial factors. But I wouldn't say enterprise adoption has outperformed expectations. I would say it's largely on track and starting to inflect up. In general, though, the train continues to accelerate down the tracks.\n",
      "I want to get your sense for sentiment on AI today. There's been a lot of ups and downs in the world. When it comes to AI, it’s specifically been in the form of DeepSeek, but more broadly, of course, tariffs and more. You're based in the Bay Area. But you spend a ton of time visiting with our clients all over the world. What are you hearing?\n",
      "I said when we chatted last that almost every observer I talked to or met with was uniformly bullish, with a few exceptions. I'm sure, and as you know, at the same time I had predicted that there would be troughs of despair or concern along the way. And there’s an Economist article out this week with that in the title. So, I suppose that was slightly predictive.\n",
      "I think overall opinion is slightly more measured now. You find plenty of bulls, but also people with real questions and doubts. As I said, I think the technical progress is undeniable. I think we have found product-market fit in the area of coding assistants and coding agents. The progress there, and the impact of that, is pretty hard to dismiss.\n",
      "I think sentiment is perhaps more measured, perhaps more balanced, but still generally bullish. Interestingly, I'm just back from Europe, and I had an interesting experience. I was talking to a large room of investors, and I asked people to raise their hands if they believed that the advent of chatbots had interrupted the number of Google searches they're doing.\n",
      "And if you ask that question in Silicon Valley, every hand will go up in that room. I would say 10% to 15% of the hands went up with that audience in Europe. So, I think we're in a world that's not a flat world. It's a little bit spiky. There are places where this is more impactful, where there's more adoption, more bullishness, where there's just less engagement. \n",
      "One area where there's more engagement is China. A number of our colleagues have just returned from visits to mainland China, where they are struck by the degree of proliferation, confidence in, and impact of AI systems. You see it everywhere, from facial recognition and palm payment systems that basically remove queuing from the world to the advent of robotic taxis. AI seems have permeated that commercial environment at a really accelerated rate, which I think has meaningful implications for the US and for the world at large.\n",
      "Maybe we'll jump off the China point. We have this 90-day tariff pause that expires in July. Is this just kind of short-term macro noise that shouldn't distract from the big ball in AI land? Or could it? Could the tariffs have a meaningful impact on the AI names and AI cycle?\n",
      "I think in the first order, I would say the tariffs and trade wars, if you want to call them that, have had minimal impact on the trajectory of adoption, investment, etc. I would have expected in some ways that this economic uncertainty would have played through more. I just personally haven't seen it.\n",
      "But I think there's a more pernicious thing beneath the surface there, which is, these systems emerge from extremely complex and intricate supply chains. Jensen Huang said recently that their current, NVL72 system has about 600,000 parts, which is extraordinary. He further said that their Khyber rack, which is coming in roughly 2027, will have approximately 2.5 million parts. He didn't disclose how many of those are foreign-sourced. But there are things like interconnects, wiring, cooling, power systems, etc.\n",
      "As you know, chips right now are at least temporarily exempt from import duties. But all these other subsystem parts are often manufactured abroad, often not available from multiple geographies, hard to replicate, and will be subject to duties.\n",
      "This is an interesting thing. We've got an administration in Washington that, on the one hand, is extremely competent, bullish, and positively inclined toward AI, and sees it as a critical dimension of US competitiveness. On the other hand, they're imposing some headwinds here to progress in that area, and it's interesting to see how that all plays out.\n",
      "I'm reading a headline that you published recently: “When AI builds AI: The next great inventors might not be human.” Can you elaborate on that thesis?\n",
      "It's from an article that I wrote for Fortune. The essence of the article is that I've been really struck by the degree to which AI systems are contributing to the development, refinement, and advancement of their successors. And observers like Satya Nadella and Mark Zuckerberg and others have commented on the degree to which these systems are central to the advancement of next-generation AI.\n",
      "It comes in three or four different areas. One is that we've largely run out of human-generated data to train these machines on. And so, the machines are now being used to generate synthetic data that advances their pre- and post-training. That’s very clearly AI building AI.\n",
      "Second is this element of post-training, which in the era of reasoning models has become more and more central. Machines are doing reinforcement learning for versions of themselves. They are generating hypotheses, evaluating the quality of those hypotheses, and doing what's called rejection sampling. They're throwing out bad answers in favor of good answers and then using that to reward the model. That's obviously the use of these technologies to advance themselves.\n",
      "And then, finally, one of the things people I've heard a lot about are these small language models. Small language models are born from very large models. Very large models are then distilled by the models themselves down into smaller form factors that are maybe more domain-specific or more limited in their functionality. So, you start to add that up, it's just extraordinary the extent to which these machines are contributing to this already steep pace of progress in the technology itself.\n",
      "The inventor analogy, I think, sprang from one paragraph I had in the article which talked about a paper out of Google that described a system they've built called Co-Scientist. Co-Scientist is an agentic framework that is designed to help inventors accelerate the pace and breadth of what they can achieve. And it's a fascinating paper. I recommend it to everyone. It hints at a world in which these agentic frameworks can marshal evidence, organize the evidence, assess hypotheses critically, analyze the output of those hypotheses, and at least advance good theories for change or invention.\n",
      "But probably most frontally, they're just an extraordinary tool for humans to elevate the inventive capacity we already have.\n",
      "Last time we spoke. I said that I thought the sequence of AI for a large company was build, deploy, harvest. And you said you actually thought it'd be build, experiment, deploy harvest, where 2023 was the build, 2024 was the experiment, and 2025 was deploy. \n",
      "And so if you flashforward to today, do you still view that as kind of the right sequence and the right timing?\n",
      "I do. I think that's an observation that, hopefully, has aged well, in the sense that it's pretty clear to me, both from our own experience within Goldman, but also talking to other clients and observing the world, this is a year where we've moved from experiments to deploy at least a bounded number of production systems.\n",
      "I think you've seen a lot of advances by companies weighing in and going into production mode in these things. You've seen a few retreats. Obviously, the news about Klarna has been out there about their desire to kind of pull back a little bit from their very aggressive posture.\n",
      "My hope is that 2026 will definitely be a year of scaling, and to some extent harvesting. There's another parenthetical, which is measure. How do we actually consider the impact of these systems? And there're some challenges to that.\n",
      "I would further say, to be a little bit provocative, that I think you're already starting to see the impact of harvest, if you squint hard and look at the world. I'm sure your listeners have seen that there there’s a memo from the CEO of Shopify, in which he basically says, when you come to me asking for resources for a new initiative, you have to convince me that AI can't do it and that you need to hire humans to pursue it.\n",
      "You saw Microsoft, whose growth is accelerating, and is the very center of this, talk about laying off, I think, 6,000 people. I don't think this is coming through broadly into productivity and employment statistics. Again, if you, if you squint hard, if you look in certain local areas, probably Silicon Valley and technology being an epicenter of this, I think we're already starting to see liminal effects of this technology.\n",
      "One question relates to GS: We saw and we've heard a lot about immediate productivity enhancement with our developers, and with our coders. When you look elsewhere around the firm, can you find other evidence of real productivity, real progress?\n",
      "We're in a bit of a unique position as a big incumbent company in a highly regulated industry. So, we've had to be careful, thoughtful, and deliberate as we roll this stuff out, working closely with our regulators, our risk and compliance people. And we've made a number of systems available to broader populations beyond engineers. I get to see the weekly adoption statistics, and they're pretty impressive.\n",
      "The data suggests to me that people are finding adoption. And again, we've moved from experiment to production of certain AI tools at Goldman. I think 2026, and beyond are the years where we're really going to observe people being better, faster, smarter, more efficient, serving clients better and coming up with more ideas by leveraging these technologies. So, again, early progress.  I see it inflecting up a little bit — I’m beginning to see that in the numbers at Goldman.\n",
      "We'll end with an informal question, as we always do. If AI could take over one routine task for you, what would it be?\n",
      "I'll give you a business one and a personal one in business.\n",
      "You and I are both generationally appropriate for an X-Files reference. One of the rallying cries in X Files is, “the truth is out there.” And inside Goldman Sachs there is such a plethora of data, you could answer almost any question you might have from information resources that exist across our firm. That ability to have a central place where I can go, ask and get answers and get access to that incredible breadth of data and information and perspectives, that to me is the ultimate for a knowledge worker, the ultimate killer app. And we're making progress toward that, with the appropriate controls and guardrails. You'll be greeted with a blinking chatbot at your desktop, and you can ask anything and get access to any piece of information that exists around the firm, if it's compliance appropriate.\n",
      "Personally, I think the thing I'm looking forward to would be really ambient systems. So rather than being anchored to my phone or my PC, having something that's sort of ever-present around me, that can do things like remind me of things and prompt me for things, or course correct things. I think that breaking free of the tyranny of our devices and having more ambient sources of intelligence would be super cool. That's many years in the future. But that’d be very fun and very useful.\n",
      " \n",
      "This material is provided in conjunction with the associated video/audio content for convenience.  The content of this material may differ from the associated video/audio and Goldman Sachs is not responsible for any errors in the material. The views expressed in this material are not necessarily those of Goldman Sachs or its affiliates. This material should not be copied, distributed, published, or reproduced, in whole or in part, or disclosed by any recipient to any other person. The information contained in this material does not constitute a recommendation from any Goldman Sachs entity to the recipient, and Goldman Sachs is not providing any financial, economic, legal, investment, accounting, or tax advice through this program or to its recipient. Neither Goldman Sachs nor any of its affiliates makes any representation or warranty, express or implied, as to the accuracy or completeness of the statements or any information contained in this material and any liability therefore (including in respect of direct, indirect, or consequential loss or damage) is expressly disclaimed.\n",
      "\n",
      " © 2025 Goldman Sachs. All rights reserved.\n",
      "Related TagsArtificial IntelligenceSubscribe to BriefingsOur signature newsletter with insights and analysis from across the firm\n",
      "Submitarrow_right_altBy submitting this information, you agree that the information you are providing is subject to Goldman Sachs’  privacy policy and Terms of Use. You consent to receive our newletter via email. \n",
      "\n",
      "© 2025 Goldman Sachs. All rights reserved.' metadata={'source': 'https://www.goldmansachs.com/insights/articles/the-outlook-for-ai-adoption-as-advancements-in-the-technology-accelerate', 'title': 'The outlook for AI adoption as advancements in the technology accelerate  | Goldman Sachs', 'description': 'There are signs that AI is exceeding even the bullish expectations of 2024 in terms of model usage and investment.', 'language': 'en-US'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5089026",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = WebBaseLoader(\"https://en.wikipedia.org/wiki/Star_Wars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "849a809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2 = loader2.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695dbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21404c8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mloader2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(doc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/langchain_core/document_loaders/base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/langchain_community/document_loaders/web_base.py:375\u001b[39m, in \u001b[36mWebBaseLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Lazy load text from the url(s) in web_path.\"\"\"\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.web_paths:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     soup = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbs_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m     text = soup.get_text(**\u001b[38;5;28mself\u001b[39m.bs_get_text_kwargs)\n\u001b[32m    377\u001b[39m     metadata = _build_metadata(soup, path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/langchain_community/document_loaders/web_base.py:357\u001b[39m, in \u001b[36mWebBaseLoader._scrape\u001b[39m\u001b[34m(self, url, parser, bs_kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m         parser = \u001b[38;5;28mself\u001b[39m.default_parser\n\u001b[32m    355\u001b[39m \u001b[38;5;28mself\u001b[39m._check_parser(parser)\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m html_doc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequests_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_for_status:\n\u001b[32m    359\u001b[39m     html_doc.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    752\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    755\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Graph-Knowledge-Creator/.venv/lib/python3.13/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m     75\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for doc in loader2.load():\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a16f644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"## Bylo sobie zycie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed8effb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bylo sobie zycie'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"##\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e34deb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7d10204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bylo sobie zycie'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[!@#$]', '', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b527761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bylo sobie zycie'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(\"##\", '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ee2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
